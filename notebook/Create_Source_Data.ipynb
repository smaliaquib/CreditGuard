{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39546674-7627-4c56-bb5e-00ca7dba8f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from pyspark.sql import SparkSession\n",
    "from databricks.connect import DatabricksSession\n",
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c043cd9-50ab-4e7d-af52-b9a4db9ddcf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = DatabricksSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7404338-87a3-43a1-9d9a-2adb8870906b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-04 15:50:57.875\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mutils\u001B[0m:\u001B[36mload_config\u001B[0m:\u001B[36m66\u001B[0m - \u001B[1mLoaded configuration from ../project_config.yml\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config(\"../project_config.yml\")\n",
    "catalog_name = config.catalog_name\n",
    "schema_name = config.schema_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9d84a9e-c33d-4138-8909-6b619750b569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 37354 is the original number of rows in the features_balanced after first SMOTE\n",
    "# 100 is the number of synthetic rows to generate each time running this notebook\n",
    "# Load train and test sets\n",
    "features_balanced = spark.table(f\"{catalog_name}.{schema_name}.features_balanced\").toPandas()\n",
    "existing_ids = set(int(id) for id in features_balanced[\"Id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "649ec2f2-d0c1-4875-ac63-c9cd7a54ee5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "37454"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6c4030-cf46-4bba-8869-96ce87c98f8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 43454)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(existing_ids), max(existing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "219d8a2d-b65b-4dac-901f-3623bb1b8be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sex     Education  ...                     Pay_6 Default\n0  [2, 1]  [1, 2, 3, 4]  ...  [0, 4, 2, 3, 7, 5, 6, 8]  [0, 1]\n\n[1 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Generate a dataframe with unique values for each column with few unique values\n",
    "# to identify the discrete values\n",
    "def generate_unique_values_dataframe(df, columns):\n",
    "    unique_values = {col: df[col].dropna().unique().tolist() for col in columns}\n",
    "    return pd.DataFrame([unique_values])\n",
    "\n",
    "\n",
    "# Load train and test sets\n",
    "train_set = spark.table(f\"{catalog_name}.{schema_name}.train_set\").toPandas()\n",
    "test_set = spark.table(f\"{catalog_name}.{schema_name}.test_set\").toPandas()\n",
    "combined_set = pd.concat([train_set, test_set], ignore_index=True)\n",
    "\n",
    "# Columns with few unique values (Age is the largest with 56 unique values)\n",
    "columns = [\"Sex\", \"Education\", \"Marriage\", \"Age\", \"Pay_0\", \"Pay_2\", \"Pay_3\", \"Pay_4\", \"Pay_5\", \"Pay_6\", \"Default\"]\n",
    "\n",
    "result = generate_unique_values_dataframe(combined_set, columns)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55788d3e-fb14-4a58-baf0-e9d4b60c8d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define function to create synthetic data without random state\n",
    "# This will add some data drift in the Bill_amt columns\n",
    "def create_synthetic_data(df, num_rows=100):\n",
    "    synthetic_data = pd.DataFrame()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]) and column != \"Id\":\n",
    "            # Check if the column has a small set of discrete values\n",
    "            unique_values = df[column].unique()\n",
    "            if len(unique_values) <= 10:  # Assume discrete values if there are 10 or fewer unique values\n",
    "                # This includes all above columns except \"Age\"\n",
    "                synthetic_data[column] = np.random.choice(unique_values, num_rows)\n",
    "            elif column.startswith(\"Pay_amt\"):  # Ensure positive values for \"Pay_amt\" columns\n",
    "                mean, std = df[column].mean(), df[column].std()\n",
    "                synthetic_data[column] = np.abs(np.random.normal(mean, std, num_rows)).astype(int).astype(float)\n",
    "            else:\n",
    "                # This will add some data drift in the Bill_amt columns\n",
    "                mean, std = df[column].mean(), df[column].std()\n",
    "                synthetic_data[column] = np.round(np.random.normal(mean, std, num_rows)).astype(int).astype(float)\n",
    "\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "            min_date, max_date = df[column].min(), df[column].max()\n",
    "            if min_date < max_date:\n",
    "                # Ensure the timestamp is between max_date and current time\n",
    "                current_time = pd.to_datetime(\"now\")\n",
    "                if max_date < current_time:\n",
    "                    timestamp_range_start = max_date.value\n",
    "                    timestamp_range_end = current_time.value\n",
    "                    synthetic_data[column] = pd.to_datetime(\n",
    "                        np.random.randint(timestamp_range_start, timestamp_range_end, num_rows)\n",
    "                    )\n",
    "                else:\n",
    "                    synthetic_data[column] = [max_date] * num_rows\n",
    "            else:\n",
    "                synthetic_data[column] = [min_date] * num_rows\n",
    "\n",
    "    new_ids = []\n",
    "    # The first synthetic Id must be one greater than the maximum existing Id of the whole dataframe (train + test). If no existing_ids, then starts from 1.\n",
    "    i = max(existing_ids) + 1 if existing_ids else 1\n",
    "\n",
    "    while len(new_ids) < num_rows:\n",
    "        if i not in existing_ids:\n",
    "            new_ids.append(str(i))  # Convert numeric ID to string\n",
    "        i += 1\n",
    "\n",
    "    synthetic_data[\"Id\"] = new_ids\n",
    "\n",
    "    return synthetic_data\n",
    "\n",
    "\n",
    "# Create synthetic data\n",
    "synthetic_df = create_synthetic_data(combined_set)\n",
    "\n",
    "# Move \"Id\" to the first position\n",
    "columns = [\"Id\"] + [col for col in synthetic_df.columns if col != \"Id\"]\n",
    "synthetic_df = synthetic_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68f376e2-7455-498d-aeae-f4ecb9c1a3ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Limit_bal</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marriage</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pay_0</th>\n",
       "      <th>Pay_2</th>\n",
       "      <th>Pay_3</th>\n",
       "      <th>Pay_4</th>\n",
       "      <th>Pay_5</th>\n",
       "      <th>Pay_6</th>\n",
       "      <th>Bill_amt1</th>\n",
       "      <th>Bill_amt2</th>\n",
       "      <th>Bill_amt3</th>\n",
       "      <th>Bill_amt4</th>\n",
       "      <th>Bill_amt5</th>\n",
       "      <th>Bill_amt6</th>\n",
       "      <th>Pay_amt1</th>\n",
       "      <th>Pay_amt2</th>\n",
       "      <th>Pay_amt3</th>\n",
       "      <th>Pay_amt4</th>\n",
       "      <th>Pay_amt5</th>\n",
       "      <th>Pay_amt6</th>\n",
       "      <th>Default</th>\n",
       "      <th>Update_timestamp_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>43550</td>\n",
       "      <td>413409.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-26706.0</td>\n",
       "      <td>12926.0</td>\n",
       "      <td>28517.0</td>\n",
       "      <td>116337.0</td>\n",
       "      <td>26948.0</td>\n",
       "      <td>2789.0</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>10296.0</td>\n",
       "      <td>3465.0</td>\n",
       "      <td>49329.0</td>\n",
       "      <td>15811.0</td>\n",
       "      <td>19563.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-04 15:39:01.397376499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>43551</td>\n",
       "      <td>157063.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>90208.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>56751.0</td>\n",
       "      <td>36949.0</td>\n",
       "      <td>-16655.0</td>\n",
       "      <td>131872.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>13592.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>3415.0</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>11661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04 15:38:18.388616934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>43552</td>\n",
       "      <td>55968.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>192931.0</td>\n",
       "      <td>4935.0</td>\n",
       "      <td>81068.0</td>\n",
       "      <td>55208.0</td>\n",
       "      <td>138627.0</td>\n",
       "      <td>55194.0</td>\n",
       "      <td>15084.0</td>\n",
       "      <td>6727.0</td>\n",
       "      <td>10345.0</td>\n",
       "      <td>19466.0</td>\n",
       "      <td>6511.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04 15:45:58.539260652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>43553</td>\n",
       "      <td>247942.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>98777.0</td>\n",
       "      <td>56354.0</td>\n",
       "      <td>43757.0</td>\n",
       "      <td>25849.0</td>\n",
       "      <td>-34255.0</td>\n",
       "      <td>-1745.0</td>\n",
       "      <td>29691.0</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>8003.0</td>\n",
       "      <td>32033.0</td>\n",
       "      <td>14128.0</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-04 15:35:09.449300281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>43554</td>\n",
       "      <td>9141.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>31020.0</td>\n",
       "      <td>-41799.0</td>\n",
       "      <td>-143495.0</td>\n",
       "      <td>93446.0</td>\n",
       "      <td>70034.0</td>\n",
       "      <td>124695.0</td>\n",
       "      <td>18955.0</td>\n",
       "      <td>11521.0</td>\n",
       "      <td>13996.0</td>\n",
       "      <td>22022.0</td>\n",
       "      <td>2369.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-04 15:32:14.135841129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Limit_bal  Sex  ...  Pay_amt6  Default          Update_timestamp_utc\n",
       "95  43550   413409.0    2  ...   19563.0        1 2025-04-04 15:39:01.397376499\n",
       "96  43551   157063.0    1  ...   11661.0        0 2025-04-04 15:38:18.388616934\n",
       "97  43552    55968.0    1  ...    1195.0        0 2025-04-04 15:45:58.539260652\n",
       "98  43553   247942.0    2  ...   10004.0        1 2025-04-04 15:35:09.449300281\n",
       "99  43554     9141.0    2  ...    3449.0        0 2025-04-04 15:32:14.135841129\n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9f10afd-4157-4936-babb-7a089e6c4275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['43455',\n",
       " '43456',\n",
       " '43457',\n",
       " '43458',\n",
       " '43459',\n",
       " '43460',\n",
       " '43461',\n",
       " '43462',\n",
       " '43463',\n",
       " '43464',\n",
       " '43465',\n",
       " '43466',\n",
       " '43467',\n",
       " '43468',\n",
       " '43469',\n",
       " '43470',\n",
       " '43471',\n",
       " '43472',\n",
       " '43473',\n",
       " '43474',\n",
       " '43475',\n",
       " '43476',\n",
       " '43477',\n",
       " '43478',\n",
       " '43479',\n",
       " '43480',\n",
       " '43481',\n",
       " '43482',\n",
       " '43483',\n",
       " '43484',\n",
       " '43485',\n",
       " '43486',\n",
       " '43487',\n",
       " '43488',\n",
       " '43489',\n",
       " '43490',\n",
       " '43491',\n",
       " '43492',\n",
       " '43493',\n",
       " '43494',\n",
       " '43495',\n",
       " '43496',\n",
       " '43497',\n",
       " '43498',\n",
       " '43499',\n",
       " '43500',\n",
       " '43501',\n",
       " '43502',\n",
       " '43503',\n",
       " '43504',\n",
       " '43505',\n",
       " '43506',\n",
       " '43507',\n",
       " '43508',\n",
       " '43509',\n",
       " '43510',\n",
       " '43511',\n",
       " '43512',\n",
       " '43513',\n",
       " '43514',\n",
       " '43515',\n",
       " '43516',\n",
       " '43517',\n",
       " '43518',\n",
       " '43519',\n",
       " '43520',\n",
       " '43521',\n",
       " '43522',\n",
       " '43523',\n",
       " '43524',\n",
       " '43525',\n",
       " '43526',\n",
       " '43527',\n",
       " '43528',\n",
       " '43529',\n",
       " '43530',\n",
       " '43531',\n",
       " '43532',\n",
       " '43533',\n",
       " '43534',\n",
       " '43535',\n",
       " '43536',\n",
       " '43537',\n",
       " '43538',\n",
       " '43539',\n",
       " '43540',\n",
       " '43541',\n",
       " '43542',\n",
       " '43543',\n",
       " '43544',\n",
       " '43545',\n",
       " '43546',\n",
       " '43547',\n",
       " '43548',\n",
       " '43549',\n",
       " '43550',\n",
       " '43551',\n",
       " '43552',\n",
       " '43553',\n",
       " '43554']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(synthetic_df.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017db42c-4423-443b-a1fb-0e7f511b508d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-139883.0, 983931.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_set.Bill_amt2.min(), combined_set.Bill_amt2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dfe151f-3790-4004-90e9-13bba01ba0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-90425.0, 191342.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some values are outside the original column names (data drift)\n",
    "synthetic_df.Bill_amt2.min(), synthetic_df.Bill_amt2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70208c76-c245-4bf3-9d6b-e5a4709b46d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100 entries, 0 to 99\nData columns (total 26 columns):\n #   Column                Non-Null Count  Dtype         \n---  ------                --------------  -----         \n 0   Id                    100 non-null    object        \n 1   Limit_bal             100 non-null    float64       \n 2   Sex                   100 non-null    int32         \n 3   Education             100 non-null    int32         \n 4   Marriage              100 non-null    int32         \n 5   Age                   100 non-null    float64       \n 6   Pay_0                 100 non-null    int32         \n 7   Pay_2                 100 non-null    int32         \n 8   Pay_3                 100 non-null    int32         \n 9   Pay_4                 100 non-null    int32         \n 10  Pay_5                 100 non-null    int32         \n 11  Pay_6                 100 non-null    int32         \n 12  Bill_amt1             100 non-null    float64       \n 13  Bill_amt2             100 non-null    float64       \n 14  Bill_amt3             100 non-null    float64       \n 15  Bill_amt4             100 non-null    float64       \n 16  Bill_amt5             100 non-null    float64       \n 17  Bill_amt6             100 non-null    float64       \n 18  Pay_amt1              100 non-null    float64       \n 19  Pay_amt2              100 non-null    float64       \n 20  Pay_amt3              100 non-null    float64       \n 21  Pay_amt4              100 non-null    float64       \n 22  Pay_amt5              100 non-null    float64       \n 23  Pay_amt6              100 non-null    float64       \n 24  Default               100 non-null    int32         \n 25  Update_timestamp_utc  100 non-null    datetime64[ns]\ndtypes: datetime64[ns](1), float64(14), int32(10), object(1)\nmemory usage: 16.5+ KB\n"
     ]
    }
   ],
   "source": [
    "synthetic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865eb430-b9bf-4bdf-93e0-1937744bec09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty table 'credit.default.source_data' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create source_data table with the same schema as train_set\n",
    "train_set_schema = spark.table(f\"{catalog_name}.{schema_name}.train_set\").schema\n",
    "\n",
    "# Create an empty DataFrame with the same schema\n",
    "empty_source_data_df = spark.createDataFrame(data=[], schema=train_set_schema)\n",
    "\n",
    "# Create an empty source_data table\n",
    "empty_source_data_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{schema_name}.source_data\")\n",
    "\n",
    "print(f\"Empty table '{catalog_name}.{schema_name}.source_data' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9430bed6-8937-480a-92bc-5c38c19a4962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "existing_schema = spark.table(f\"{catalog_name}.{schema_name}.source_data\").schema\n",
    "\n",
    "synthetic_spark_df = spark.createDataFrame(synthetic_df, schema=existing_schema)\n",
    "\n",
    "# Append synthetic data as new data to source_data table\n",
    "synthetic_spark_df.write.mode(\"append\").saveAsTable(f\"{catalog_name}.{schema_name}.source_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8c45a5-77a8-42c0-a0d7-1677856000f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06. Create_Source_Data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}